{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c5475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3df5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('custs_with_overlay',), ('growth_groups',), ('hu_block',), ('hu_block_group',), ('hu_block_group_indexes',), ('hu_boundary_artifacts',), ('hu_cbsa',), ('hu_cbsa_indexes',), ('hu_county',), ('hu_county_indexes',), ('hu_cousub',), ('hu_cousub_indexes',), ('hu_place',), ('hu_place_indexes',), ('hu_state',), ('hu_tract',), ('hu_tract_indexes',), ('hu_ua',), ('hu_us',), ('hu_zcta',), ('hu_zcta_indexes',), ('metadata',), ('newer_growth_groups',)]\n",
      "         tract  HU_20  gq_20  HU_24  gq_24  HU_25  gq_25  block_recs  \\\n",
      "0  01001020100    719      0    728      0    734      0          56   \n",
      "1  01001020200    806      1    825      1    841      1          41   \n",
      "2  01001020300   1391      2   1429      2   1432      2          42   \n",
      "3  01001020400   1812      0   1798      0   1796      2          92   \n",
      "4  01001020501   1847      3   1963      3   1963      4          47   \n",
      "\n",
      "  state_code  hg_20_24  hgi_20_24  cagr_20_24  hg_24_25    hgi_25    agr_25  \\\n",
      "0         01         9   1.012517    0.002877         6  1.008242  0.008242   \n",
      "1         01        19   1.023573    0.005395        16  1.019394  0.019394   \n",
      "2         01        38   1.027318    0.006244         3  1.002099  0.002099   \n",
      "3         01       -14   0.992274   -0.001790        -2  0.998888 -0.001112   \n",
      "4         01       116   1.062805    0.014167         0  1.000000  0.000000   \n",
      "\n",
      "   hg_20_25  hgi_20_25  cagr_20_25  \n",
      "0        15   1.020862    0.003881  \n",
      "1        35   1.043424    0.008007  \n",
      "2        41   1.029475    0.005465  \n",
      "3       -16   0.991170   -0.001663  \n",
      "4       116   1.062805    0.011494  \n",
      "[('bg_boundary_artifacts',), ('geo_block_group',), ('geo_block_group_00',), ('geo_block_group_10',), ('geo_block_group_23',), ('geo_cbsa',), ('geo_cbsa_10',), ('geo_cbsa_23',), ('geo_cosub',), ('geo_cosub_10',), ('geo_cosub_23',), ('geo_counties_mn',), ('geo_county',), ('geo_county_00',), ('geo_county_10',), ('geo_county_23',), ('geo_place',), ('geo_place_14',), ('geo_place_23',), ('geo_state',), ('geo_table_metadata',), ('geo_tract',), ('geo_tract_00',), ('geo_tract_10',), ('geo_tract_23',), ('geo_zcta',)]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"/home/joel\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "### DUCKDB CONNECTION\n",
    "\n",
    "conh = duckdb.connect('./data/housing.duckdb')\n",
    "print(conh.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall())\n",
    "\n",
    "# Test query\n",
    "print(conh.execute(\"SELECT * FROM hu_tract LIMIT 5\").df())\n",
    "\n",
    "\n",
    "### THIS SUPPLIES THE BLOCK TO COUNTY SUBDIVISION, BLOCK TO PLACE, AND BLOCK TO URBAN AREA LOOKUPS\n",
    "\n",
    "congref = duckdb.connect(\n",
    "    './data/georeference.duckdb',\n",
    "    read_only=False\n",
    ")\n",
    "congref.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "\n",
    "congeo = duckdb.connect(\n",
    "    './data/spatial_storage.duckdb',\n",
    "    read_only=False\n",
    ")\n",
    "congeo.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "\n",
    "print(congeo.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall())\n",
    "\n",
    "place_look = pl.from_pandas(\n",
    "    congref.execute(\"SELECT geoid, place, placename, county FROM block_place\").df()\n",
    ")\n",
    "\n",
    "place_unique = place_look.group_by(\"placename\").agg(\n",
    "    pl.col(\"place\").unique()\n",
    ")\n",
    "\n",
    "cousub_look = pl.from_pandas(\n",
    "    congref.execute(\n",
    "        \"SELECT geoid, cousub20 AS cousub, mcdname, county AS co_fips FROM block_cosub\"\n",
    "    ).df()\n",
    ")\n",
    "\n",
    "ua_look = pl.from_pandas(\n",
    "    congref.execute(\"SELECT geoid, ua, uaname, county FROM block_ua\").df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1be70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read county metadata\n",
    "# use adjacency file for convenience\n",
    "co_id = pl.from_pandas(\n",
    "    conh.execute(\n",
    "        \"\"\"SELECT * FROM read_csv_auto(\n",
    "        './data/geo/county-adjacency.txt', header=True, normalize_names=True\n",
    "        )\"\"\"\n",
    "    ).df()\n",
    ")\n",
    "\n",
    "county_ids = co_id.group_by(\"county_name\").agg(\n",
    "    pl.col(\"county_geoid\").max().alias(\"fipscode\")\n",
    ")\n",
    "\n",
    "### LOAD BLOCK MAPPING DATA FOR CONNECTICUT FIPS '09'\n",
    "\n",
    "ct_remap_id = pl.from_pandas(\n",
    "    congref.execute(\n",
    "        \"\"\"SELECT block_fips_2020, block_fips_2022 FROM read_csv_auto(\n",
    "        './data/ct-2022blockcrosswalk.csv', header=True, normalize_names=True\n",
    "        )\"\"\"\n",
    "    ).df()\n",
    ")\n",
    "\n",
    "#### BLOCK TO ZCTA RELATIONSHIPS\n",
    "\n",
    "block_to_zcta = pl.from_pandas(\n",
    "    congref.execute(\n",
    "        \"\"\"SELECT GEOID_TABBLOCK_20 as block_geoid, GEOID_ZCTA5_20 as zcta_20\n",
    "        FROM read_csv_auto('./data/geo/tab20_zcta520_tabblock20_natl.txt',\n",
    "        header=True, normalize_names=True)\"\"\"\n",
    "    ).df()\n",
    ").filter(pl.col(\"zcta_20\").is_not_null())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85721beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "\n",
    "# Function to process data for a single state\n",
    "def state_HU_data(state_code, state_name):\n",
    "    \"\"\"Process housing unit data for a single state\"\"\"\n",
    "    \n",
    "    # Read 2020 data\n",
    "    HU_20 = pl.from_pandas(\n",
    "        conh.execute(\n",
    "            f\"\"\"SELECT * FROM read_csv_auto(\n",
    "                './data/geo/{state_code}_{state_name}_AddressBlockCountList_062022.txt',\n",
    "                header=True,\n",
    "                normalize_names=True,\n",
    "                all_varchar=True)\"\"\"\n",
    "        ).df()\n",
    "    ).select([\"block_geoid\", \"total_housing_units\", \"total_group_quarters\"])\n",
    "    \n",
    "    HU_20 = HU_20.sort(\"total_housing_units\", descending=True)\n",
    "    \n",
    "    # Read 2023 data; represents growth April 2020 - November 2023 (published 2024)\n",
    "    HU_24 = pl.from_pandas(\n",
    "        conh.execute(\n",
    "            f\"\"\"SELECT * FROM read_csv_auto(\n",
    "                './data/geo/{state_code}_{state_name}_AddressBlockCountList_072024.txt',\n",
    "                header=True,\n",
    "                normalize_names=True,\n",
    "                all_varchar=True)\"\"\"\n",
    "        ).df()\n",
    "    ).select([\"block_geoid\", \"total_housing_units\", \"total_group_quarters\"])\n",
    "    \n",
    "    HU_24 = HU_24.sort(\"total_housing_units\", descending=True)\n",
    "\n",
    "    ## LATEST, RELEASED SEPTEMBER 2025\n",
    "    HU_25 = pl.from_pandas(\n",
    "        conh.execute(\n",
    "            f\"\"\"SELECT * FROM read_csv_auto(\n",
    "                './data/geo/{state_code}_{state_name}_AddressBlockCountList_072025.txt',\n",
    "                header=True,\n",
    "                normalize_names=True,\n",
    "                all_varchar=True)\"\"\"\n",
    "        ).df()\n",
    "    ).select([\"block_geoid\", \"total_housing_units\", \"total_group_quarters\"])\n",
    "    \n",
    "    HU_25 = HU_25.sort(\"total_housing_units\", descending=True)\n",
    "\n",
    "    # Rename columns\n",
    "    HU_20 = HU_20.rename({\"total_housing_units\": \"HU_20\", \"total_group_quarters\": \"gq_20\"})\n",
    "    HU_24 = HU_24.rename({\"total_housing_units\": \"HU_24\", \"total_group_quarters\": \"gq_24\"})\n",
    "    HU_25 = HU_25.rename({\"total_housing_units\": \"HU_25\", \"total_group_quarters\": \"gq_25\"})\n",
    "\n",
    "    # Filter records where 'block_geoid' contains the exact string \"TOTAL\"\n",
    "    HU_20 = HU_20.filter(~pl.col(\"block_geoid\").str.contains(\"TOTAL\"))\n",
    "    HU_24 = HU_24.filter(~pl.col(\"block_geoid\").str.contains(\"TOTAL\"))\n",
    "    HU_25 = HU_25.filter(~pl.col(\"block_geoid\").str.contains(\"TOTAL\"))\n",
    "\n",
    "    # Convert to integer\n",
    "    HU_20 = HU_20.with_columns([\n",
    "        pl.col(\"HU_20\").cast(pl.Int64),\n",
    "        pl.col(\"gq_20\").cast(pl.Int64)\n",
    "    ])\n",
    "    HU_24 = HU_24.with_columns([\n",
    "        pl.col(\"HU_24\").cast(pl.Int64),\n",
    "        pl.col(\"gq_24\").cast(pl.Int64)\n",
    "    ])\n",
    "    HU_25 = HU_25.with_columns([\n",
    "        pl.col(\"HU_25\").cast(pl.Int64),\n",
    "        pl.col(\"gq_25\").cast(pl.Int64)\n",
    "    ])\n",
    "\n",
    "    # Merge data from all three years\n",
    "    HU_merged = HU_20.join(HU_24, on=\"block_geoid\", how=\"full\", coalesce=True)\n",
    "    HU_merged = HU_merged.join(HU_25, on=\"block_geoid\", how=\"full\", coalesce=True)\n",
    "    \n",
    "    # Block aggregation - required because of block-part records\n",
    "    HU_block = HU_merged.with_columns(\n",
    "        pl.col(\"block_geoid\").str.slice(0, 15).alias(\"block_geoid_15\")\n",
    "    ).group_by(\"block_geoid_15\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_part_recs\")\n",
    "    ]).rename({\"block_geoid_15\": \"block_geoid\"})\n",
    "\n",
    "    # Merge with block_to_zcta\n",
    "    HU_block = HU_block.join(\n",
    "        block_to_zcta,\n",
    "        on=\"block_geoid\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    HU_block = HU_block.join(\n",
    "        ct_remap_id,\n",
    "        left_on=\"block_geoid\",\n",
    "        right_on=\"block_fips_2020\",\n",
    "        how=\"left\"\n",
    "    )\n",
    " \n",
    "    # INSERT AUG 2025:\n",
    "    # HIERARCHIES FOR COUNTY SUB, PLACE, URBAN AREA\n",
    "\n",
    "    HU_block = HU_block.join(\n",
    "        ua_look,\n",
    "        left_on=\"block_geoid\",\n",
    "        right_on=\"geoid\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    HU_block = HU_block.join(\n",
    "        place_look,\n",
    "        left_on=\"block_geoid\",\n",
    "        right_on=\"geoid\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_place\"\n",
    "    )\n",
    "\n",
    "    HU_block = HU_block.join(\n",
    "        cousub_look,\n",
    "        left_on=\"block_geoid\",\n",
    "        right_on=\"geoid\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_cousub\"\n",
    "    )\n",
    "\n",
    "    # CONNECTICUT ONLY\n",
    "    # remap block_geoid to block_fips_2022\n",
    "    HU_block = HU_block.with_columns(\n",
    "        pl.when(pl.col(\"block_geoid\").str.slice(0, 2) == \"09\")\n",
    "        .then(pl.col(\"block_fips_2022\"))\n",
    "        .otherwise(pl.col(\"block_geoid\"))\n",
    "        .alias(\"block_geoid\")\n",
    "    )\n",
    "\n",
    "    # Block group level aggregation\n",
    "    HU_bg = HU_block.with_columns(\n",
    "        pl.col(\"block_geoid\").str.slice(0, 12).alias(\"block_group\")\n",
    "    ).group_by(\"block_group\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Add state information to block group\n",
    "    HU_bg = HU_bg.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    # Tract level aggregation\n",
    "    HU_tract = HU_block.with_columns(\n",
    "        pl.col(\"block_geoid\").str.slice(0, 11).alias(\"tract\")\n",
    "    ).group_by(\"tract\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Add state information to tract\n",
    "    HU_tract = HU_tract.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    # County level aggregation\n",
    "    HU_co = HU_block.with_columns(\n",
    "        pl.col(\"block_geoid\").str.slice(0, 5).alias(\"co_fips\")\n",
    "    ).group_by(\"co_fips\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Attach county names\n",
    "    HU_co = HU_co.join(county_ids, left_on=\"co_fips\", right_on=\"fipscode\", how=\"left\")\n",
    "\n",
    "    # Add state information\n",
    "    HU_co = HU_co.with_columns([\n",
    "        pl.lit(state_code).alias(\"state_code\"),\n",
    "        pl.lit(state_name).alias(\"state_name\")\n",
    "    ])\n",
    "\n",
    "    # ZCTA level aggregation\n",
    "    HU_zcta = HU_block.group_by(\"zcta_20\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Add state information to ZCTA\n",
    "    HU_zcta = HU_zcta.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    ## COUSUB ########################################################################\n",
    "\n",
    "    HU_cousub = HU_block.group_by([\"co_fips\", \"cousub\"]).agg([\n",
    "      pl.col(\"HU_20\").sum(),\n",
    "      pl.col(\"gq_20\").sum(),\n",
    "      pl.col(\"HU_24\").sum(),\n",
    "      pl.col(\"gq_24\").sum(),\n",
    "      pl.col(\"HU_25\").sum(),\n",
    "      pl.col(\"gq_25\").sum(),\n",
    "      pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Add state information to county subdivision\n",
    "    HU_cousub = HU_cousub.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    ## PLACE ########################################################################\n",
    "\n",
    "    HU_place = HU_block.group_by(\"place\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "\n",
    "    # Add state information to place\n",
    "    HU_place = HU_place.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    ## URBAN AREA ########################################################################\n",
    "\n",
    "    HU_ua = HU_block.group_by(\"ua\").agg([\n",
    "        pl.col(\"HU_20\").sum(),\n",
    "        pl.col(\"gq_20\").sum(),\n",
    "        pl.col(\"HU_24\").sum(),\n",
    "        pl.col(\"gq_24\").sum(),\n",
    "        pl.col(\"HU_25\").sum(),\n",
    "        pl.col(\"gq_25\").sum(),\n",
    "        pl.count().alias(\"block_recs\")\n",
    "    ])\n",
    "    \n",
    "    # Add state information to urban area\n",
    "    HU_ua = HU_ua.with_columns(pl.lit(state_code).alias(\"state_code\"))\n",
    "\n",
    "    # Return all data tables\n",
    "    return {\n",
    "        \"block\": HU_block,\n",
    "        \"block_group\": HU_bg,\n",
    "        \"tract\": HU_tract,\n",
    "        \"county\": HU_co,\n",
    "        \"zcta\": HU_zcta,\n",
    "        \"cousub\": HU_cousub,\n",
    "        \"place\": HU_place,\n",
    "        \"ua\": HU_ua\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f304b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Alabama ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35283/3495128413.py:84: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_part_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:146: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:162: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:178: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:198: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:213: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:228: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:243: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:146: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:162: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:178: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:198: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:213: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:228: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n",
      "/tmp/ipykernel_35283/3495128413.py:243: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"block_recs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Alaska ...\n",
      "Processing Arizona ...\n",
      "Processing Arizona ...\n",
      "Processing Arkansas ...\n",
      "Processing Arkansas ...\n",
      "Processing California ...\n",
      "Processing California ...\n",
      "Processing Colorado ...\n",
      "Processing Colorado ...\n",
      "Processing Connecticut ...\n",
      "Processing Connecticut ...\n",
      "Processing Delaware ...\n",
      "Processing Delaware ...\n",
      "Processing DistrictofColumbia ...\n",
      "Processing DistrictofColumbia ...\n",
      "Processing Florida ...\n",
      "Processing Florida ...\n",
      "Processing Georgia ...\n",
      "Processing Georgia ...\n",
      "Processing Hawaii ...\n",
      "Processing Hawaii ...\n",
      "Processing Idaho ...\n",
      "Processing Idaho ...\n",
      "Processing Illinois ...\n",
      "Processing Illinois ...\n",
      "Processing Indiana ...\n",
      "Processing Indiana ...\n",
      "Processing Iowa ...\n",
      "Processing Iowa ...\n",
      "Processing Kansas ...\n",
      "Processing Kansas ...\n",
      "Processing Kentucky ...\n",
      "Processing Kentucky ...\n",
      "Processing Louisiana ...\n",
      "Processing Louisiana ...\n",
      "Processing Maine ...\n",
      "Processing Maine ...\n",
      "Processing Maryland ...\n",
      "Processing Maryland ...\n",
      "Processing Massachusetts ...\n",
      "Processing Massachusetts ...\n",
      "Processing Michigan ...\n",
      "Processing Michigan ...\n",
      "Processing Minnesota ...\n",
      "Processing Minnesota ...\n",
      "Processing Mississippi ...\n",
      "Processing Mississippi ...\n",
      "Processing Missouri ...\n",
      "Processing Missouri ...\n",
      "Processing Montana ...\n",
      "Processing Montana ...\n",
      "Processing Nebraska ...\n",
      "Processing Nebraska ...\n",
      "Processing Nevada ...\n",
      "Processing Nevada ...\n",
      "Processing NewHampshire ...\n",
      "Processing NewHampshire ...\n",
      "Processing NewJersey ...\n",
      "Processing NewJersey ...\n",
      "Processing NewMexico ...\n",
      "Processing NewMexico ...\n",
      "Processing NewYork ...\n",
      "Processing NewYork ...\n",
      "Processing NorthCarolina ...\n",
      "Processing NorthCarolina ...\n",
      "Processing NorthDakota ...\n",
      "Processing NorthDakota ...\n",
      "Processing Ohio ...\n",
      "Processing Ohio ...\n",
      "Processing Oklahoma ...\n",
      "Processing Oklahoma ...\n",
      "Processing Oregon ...\n",
      "Processing Oregon ...\n",
      "Processing Pennsylvania ...\n",
      "Processing Pennsylvania ...\n",
      "Processing RhodeIsland ...\n",
      "Processing RhodeIsland ...\n",
      "Processing SouthCarolina ...\n",
      "Processing SouthCarolina ...\n",
      "Processing SouthDakota ...\n",
      "Processing SouthDakota ...\n",
      "Processing Tennessee ...\n",
      "Processing Tennessee ...\n",
      "Processing Texas ...\n",
      "Processing Texas ...\n",
      "Processing Utah ...\n",
      "Processing Utah ...\n",
      "Processing Vermont ...\n",
      "Processing Vermont ...\n",
      "Processing Virginia ...\n",
      "Processing Virginia ...\n",
      "Processing Washington ...\n",
      "Processing Washington ...\n",
      "Processing WestVirginia ...\n",
      "Processing WestVirginia ...\n",
      "Processing Wisconsin ...\n",
      "Processing Wisconsin ...\n",
      "Processing Wyoming ...\n",
      "Processing Wyoming ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of states and their codes\n",
    "states = {\n",
    "    \"01\": \"Alabama\", \"02\": \"Alaska\", \"04\": \"Arizona\", \"05\": \"Arkansas\",\n",
    "    \"06\": \"California\", \"08\": \"Colorado\", \"09\": \"Connecticut\",\n",
    "    \"10\": \"Delaware\", \"11\": \"DistrictofColumbia\", \"12\": \"Florida\",\n",
    "    \"13\": \"Georgia\", \"15\": \"Hawaii\", \"16\": \"Idaho\", \"17\": \"Illinois\",\n",
    "    \"18\": \"Indiana\", \"19\": \"Iowa\", \"20\": \"Kansas\", \"21\": \"Kentucky\",\n",
    "    \"22\": \"Louisiana\", \"23\": \"Maine\", \"24\": \"Maryland\", \"25\": \"Massachusetts\",\n",
    "    \"26\": \"Michigan\", \"27\": \"Minnesota\", \"28\": \"Mississippi\",\n",
    "    \"29\": \"Missouri\", \"30\": \"Montana\", \"31\": \"Nebraska\", \"32\": \"Nevada\",\n",
    "    \"33\": \"NewHampshire\", \"34\": \"NewJersey\", \"35\": \"NewMexico\",\n",
    "    \"36\": \"NewYork\", \"37\": \"NorthCarolina\", \"38\": \"NorthDakota\", \"39\": \"Ohio\",\n",
    "    \"40\": \"Oklahoma\", \"41\": \"Oregon\", \"42\": \"Pennsylvania\",\n",
    "    \"44\": \"RhodeIsland\", \"45\": \"SouthCarolina\", \"46\": \"SouthDakota\",\n",
    "    \"47\": \"Tennessee\", \"48\": \"Texas\", \"49\": \"Utah\", \"50\": \"Vermont\",\n",
    "    \"51\": \"Virginia\", \"53\": \"Washington\", \"54\": \"WestVirginia\",\n",
    "    \"55\": \"Wisconsin\", \"56\": \"Wyoming\"\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "all_results = {}\n",
    "block_data = {}\n",
    "block_group_data = {}\n",
    "tract_data = {}\n",
    "county_data = {}\n",
    "zcta_data = {}\n",
    "cousub_data = {}\n",
    "place_data = {}\n",
    "ua_data = {}\n",
    "\n",
    "# Process data for each state\n",
    "for state_code, state_name in states.items():\n",
    "    print(f\"Processing {state_name} ...\")\n",
    "    \n",
    "    state_results = state_HU_data(state_code, state_name)\n",
    "    \n",
    "    all_results[state_name] = state_results\n",
    "    block_data[state_name] = state_results[\"block\"]\n",
    "    block_group_data[state_name] = state_results[\"block_group\"]\n",
    "    tract_data[state_name] = state_results[\"tract\"]\n",
    "    county_data[state_name] = state_results[\"county\"]\n",
    "    zcta_data[state_name] = state_results[\"zcta\"]\n",
    "    cousub_data[state_name] = state_results[\"cousub\"]\n",
    "    place_data[state_name] = state_results[\"place\"]\n",
    "    ua_data[state_name] = state_results[\"ua\"]\n",
    "\n",
    "\n",
    "# Function to calculate ratios and CAGR for housing unit data\n",
    "def calculate_hu_indices(df):\n",
    "    \"\"\"Calculate housing unit growth indices and CAGR\"\"\"\n",
    "    return df.with_columns([\n",
    "        # 20 TO 24\n",
    "        (pl.col(\"HU_24\") - pl.col(\"HU_20\")).alias(\"hg_20_24\"),\n",
    "        (pl.col(\"HU_24\") / pl.col(\"HU_20\")).alias(\"hgi_20_24\"),\n",
    "        ((pl.col(\"HU_24\") / pl.col(\"HU_20\")) ** (1 / 4.33) - 1).alias(\"cagr_20_24\"),\n",
    "        # 24 To 25, 1 YEAR; SIMPLIFIED AGR FORMULA\n",
    "        (pl.col(\"HU_25\") - pl.col(\"HU_24\")).alias(\"hg_24_25\"),\n",
    "        (pl.col(\"HU_25\") / pl.col(\"HU_24\")).alias(\"hgi_25\"),\n",
    "        (pl.col(\"HU_25\") / pl.col(\"HU_24\") - 1).alias(\"agr_25\"),\n",
    "        # TOTAL PERIOD, 4.5 YEARS APRIL 2020 TO NOV 2024\n",
    "        (pl.col(\"HU_25\") - pl.col(\"HU_20\")).alias(\"hg_20_25\"),\n",
    "        (pl.col(\"HU_25\") / pl.col(\"HU_20\")).alias(\"hgi_20_25\"),\n",
    "        ((pl.col(\"HU_25\") / pl.col(\"HU_20\")) ** (1 / 5.33) - 1).alias(\"cagr_20_25\")\n",
    "    ])\n",
    "\n",
    "\n",
    "# Combine data for each entity type\n",
    "combined_block_data = pl.concat(list(block_data.values()))\n",
    "combined_block_group_data = pl.concat(list(block_group_data.values()))\n",
    "combined_tract_data = pl.concat(list(tract_data.values()))\n",
    "combined_county_data = pl.concat(list(county_data.values()))\n",
    "\n",
    "# For state-spanning layers, aggregate before ratio calculations\n",
    "combined_zcta_data_raw = pl.concat(list(zcta_data.values()))\n",
    "combined_cousub_data_raw = pl.concat(list(cousub_data.values()))\n",
    "combined_place_data_raw = pl.concat(list(place_data.values()))\n",
    "combined_ua_data_raw = pl.concat(list(ua_data.values()))\n",
    "\n",
    "# Aggregate ZCTA data by zcta_20 (unique key)\n",
    "combined_zcta_data = combined_zcta_data_raw.filter(\n",
    "    pl.col(\"zcta_20\").is_not_null()\n",
    ").group_by(\"zcta_20\").agg([\n",
    "    pl.col(\"HU_20\").sum(),\n",
    "    pl.col(\"gq_20\").sum(),\n",
    "    pl.col(\"HU_24\").sum(),\n",
    "    pl.col(\"gq_24\").sum(),\n",
    "    pl.col(\"HU_25\").sum(),\n",
    "    pl.col(\"gq_25\").sum(),\n",
    "    pl.col(\"block_recs\").sum(),\n",
    "    pl.col(\"state_code\").n_unique().alias(\"n_states\")\n",
    "])\n",
    "\n",
    "# Apply ratio and CAGR calculations to combined datasets\n",
    "combined_block_group_data = calculate_hu_indices(combined_block_group_data)\n",
    "combined_tract_data = calculate_hu_indices(combined_tract_data)\n",
    "combined_county_data = calculate_hu_indices(combined_county_data)\n",
    "combined_zcta_data = calculate_hu_indices(combined_zcta_data)\n",
    "combined_cousub_data = calculate_hu_indices(combined_cousub_data_raw)\n",
    "combined_place_data = calculate_hu_indices(combined_place_data_raw)\n",
    "combined_ua_data = calculate_hu_indices(combined_ua_data_raw)\n",
    "\n",
    "os.chdir(\"./data\")\n",
    "\n",
    "# Save combined data to Parquet files (Python equivalent of RDS)\n",
    "combined_block_data.write_parquet(\"combined_block_data.parquet\")\n",
    "combined_block_group_data.write_parquet(\"combined_block_group_data.parquet\")\n",
    "combined_tract_data.write_parquet(\"combined_tract_data.parquet\")\n",
    "combined_county_data.write_parquet(\"combined_county_data.parquet\")\n",
    "combined_zcta_data.write_parquet(\"combined_zcta_data.parquet\")\n",
    "combined_cousub_data.write_parquet(\"combined_cousub_data.parquet\")\n",
    "combined_place_data.write_parquet(\"combined_place_data.parquet\")\n",
    "combined_ua_data.write_parquet(\"combined_ua_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
